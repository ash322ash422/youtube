{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439327b4-49e6-443a-a958-ef7a28ceb406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hi\\AppData\\Local\\Temp\\ipykernel_4140\\1893042939.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix # for creating sparse data\n",
    "\n",
    "data_file = 'DELETE_ME_huge_file.csv' # Do NOT FORGET TO DELETE THIS AT THE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f13b61-a7da-427e-b7b7-442dad04e71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02570438-e313-400f-b322-c492f6078819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7c8b158-9162-4740-88a7-362eddca3e5a",
   "metadata": {},
   "source": [
    "# chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3101b570-c495-4012-a68d-f1f7bf808d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created DELETE_ME_huge_file.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a large CSV (5 million rows) # took 30 sec\n",
    "rows = 50_000_000\n",
    "df = pd.DataFrame({\n",
    "    \"id\": np.arange(rows),\n",
    "    \"value\": np.random.randint(0, 100, size=rows)\n",
    "})\n",
    "\n",
    "df.to_csv(data_file, index=False)\n",
    "print(f\"Successfully created {data_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "979d0c22-4ddb-42cc-ae71-9871505c085c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full load:    sum=2474891770, time=4.83 sec\n"
     ]
    }
   ],
   "source": [
    "# 2. Read at once (memory heavy)\n",
    "start   = time.process_time()\n",
    "df_full = pd.read_csv(data_file)\n",
    "total_sum_full = df_full[\"value\"].sum()\n",
    "end     = time.process_time()\n",
    "print(f\"Full load:    sum={total_sum_full}, time={end - start:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7a39582-17c5-4997-99eb-85b572ab73e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked load: sum=2474891770, time=9.61 sec\n"
     ]
    }
   ],
   "source": [
    "# 3. Read in chunks (memory light)\n",
    "start = time.process_time()\n",
    "\n",
    "total_sum_chunk = 0\n",
    "chunks = pd.read_csv(data_file, chunksize=100_000)  # 100k rows at a time\n",
    "for chunk in chunks:\n",
    "    total_sum_chunk += chunk[\"value\"].sum()\n",
    "    \n",
    "end = time.process_time()\n",
    "print(f\"Chunked load: sum={total_sum_chunk}, time={end - start:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0739979-992c-440c-87db-c81c9f9149ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conclusion\n",
    "# Both methods give the same result\n",
    "# Chunking uses far less memory (youâ€™re only holding 100k rows in memory at any given time instead of 5 million).\n",
    "# The speed may be slightly better or slightly worse depending on system I/O, but the real win is memory efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad760e5-967f-4f33-9195-9d7f2220b390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc71fa7-5297-4a35-86b1-edb9d7046f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9e2620-1e7f-411f-890b-b1712c6379aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked load: mean=49.49528002, time=6.84 sec\n"
     ]
    }
   ],
   "source": [
    "# Now lets calculate mean value using chunking: took 12 sec\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "total_sum   = 0\n",
    "total_count = 0\n",
    "\n",
    "chunks = pd.read_csv(data_file, chunksize=100_000)  # 100k rows at a time\n",
    "for chunk in chunks:\n",
    "    total_sum   += chunk[\"value\"].sum()\n",
    "    total_count += chunk[\"value\"].count()   # count non-NaN values\n",
    "\n",
    "mean_value = total_sum / total_count\n",
    "\n",
    "end = time.process_time()\n",
    "\n",
    "print(f\"Chunked load: mean={mean_value}, time={end - start:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39426b-b1c7-4263-9ba3-fbede7183aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85649378-7224-4d42-99be-09d058bab2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328f705a-a03a-4be7-b844-14a7eaebead1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a0ecf-68c9-4208-a794-27937bdc18b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f8753-2cdf-4032-86c7-e7cabd5c3238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
